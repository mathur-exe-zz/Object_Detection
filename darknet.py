# -*- coding: utf-8 -*-
"""darknet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1W4MfE1GPL9CeFhMwZ9e17zPrX1gsiEmc
"""

from __future__ import division 
import numpy as np

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable

def parse_cfg(cfgfile):
  """
  - Take a config files adn returns a list of block. 
  - Each block describes a block in nn that need to be built
  - Block is in form of a dictionary 
  
  The attribute of blocks and their values are stores as key-val pairs in dict
  
  """

  # Saving the content of the cfg file in string format
  file = open(cfgfile, 'r')
  lines = file.read().split('\n')                   # store the lines in a list 
  lines = [x for x in lines if len(x) > 0]          # ignoreing empty lines
  lines = [x for x in lines if x[0] != '#']         # get rid of comments
  lines = [x.rstrip().lstrip() for x in lines]      # get rid of whitespce to the right and left of word

  #looping over the resultant lines to bet blocks
  block = {}
  blocks = []
  for line in lines:
    if line[0] == '[':                      # '[' this marks the start of a new block
      if len(block) != 0:                   # !block.empty  --> block is storing some values 
        blocks.append(block)                # add it to blocks list
        block = {}                          # re-init the block
      block['type'] = line[1:-1]
    else:
      key, value = line.split('=')
      block[key.rstrip()] = value.lstrip()
  blocks.append(block)

  return blocks

"""
What's an empty layer?
- 
"""
class EmptyLayer(nn.Module):
    def __init__(self):
        super(EmptyLayer, self).__init__()

# used to detect bounding boxes
class DetectionLayer(nn.Module):
    def __init__(self, anchors):
        super(DetectionLayer, self).__init__()
        self.anchors = anchors

def create_modules(blocks):
  net_info = blocks[0]                # capturing info about i/p & preprocessing
  module_list = nn.ModuleList()
  prev_filters = 3                   
  # used to track the no. of filter in the layer which the convolution layer is appled
  # has been initalized to 3 filters corresponding to RGB channels
  output_filters = []     # stores the number of o/p filters 

  # iterate over the list of blocks, and create a PyTorch module for each block
  for index, x in enumerate(blocks[1:]):
    module = nn.Sequential()
  
    if (x["type"] == "convolutional"):

      """
      Convolution Layer
      - 
      """ 

      #Get the info about the layer
      activation = x["activation"]
      try:
        batch_normalize = int(x["batch_normalize"])
        bias = False
      except:
        batch_normalize = 0
        bias = True
        
      filters= int(x["filters"])
      padding = int(x["pad"])
      kernel_size = int(x["size"])
      stride = int(x["stride"])
        
      if padding:
        pad = (kernel_size - 1) // 2
      else:
        pad = 0
        
      #Add the convolutional layer
      conv = nn.Conv2d(prev_filters, filters, kernel_size, stride, pad, bias = bias)
      module.add_module("conv_{0}".format(index), conv)
        
      #Add the Batch Norm Layer
      if batch_normalize:
        bn = nn.BatchNorm2d(filters)
        module.add_module("batch_norm_{0}".format(index), bn)
        
      #Check the activation. 
      #It is either Linear or a Leaky ReLU for YOLO
      if activation == "leaky":
        activn = nn.LeakyReLU(0.1, inplace = True)
        module.add_module("leaky_{0}".format(index), activn)  
    
    elif (x["type"] == "route"):

      """
      Route Layer / Shortcut Layer
      - Extract the values of the layer attribute 
      - Cat ti into an int and store in list
      """

      x["layers"] = x["layers"].split(',')
      #Start  of a route
      start = int(x["layers"][0])
      #end, if there exists one.
      try:
        end = int(x["layers"][1])
      except:
        end = 0
      #Positive anotation
      if start > 0: 
        start = start - index
      if end > 0:
        end = end - index
      route = EmptyLayer()
      module.add_module("route_{0}".format(index), route)
      if end < 0:
        filters = output_filters[index + start] + output_filters[index + end]
      else:
        filters= output_filters[index + start]

      #shortcut corresponds to skip connection
    
    elif x["type"] == "shortcut":
      shortcut = EmptyLayer()
      module.add_module("shortcut_{}".format(index), shortcut)
  
    elif x["type"] == "yolo":
      mask = x["mask"].split(",")
      mask = [int(x) for x in mask]
      
      anchors = x["anchors"].split(",")
      anchors = [int(a) for a in anchors]
      anchors = [(anchors[i], anchors[i+1]) for i in range(0, len(anchors),2)]
      anchors = [anchors[i] for i in mask]

      detection = DetectionLayer(anchors)
      module.add_module("Detection_{}".format(index), detection)

    # Storing values in list
    module_list.append(module)
    prev_filters = filters
    output_filters.append(filters)

  return (net_info, module_list)

blocks = parse_cfg('/content/yolov3.cfg')
print(create_modules(blocks))

class Darknet(nn.Module):
  def __inint__(self, cfgfile):
    super(Darknet, self).__init__()
    self.blocks = parse_cfg(cfgfile)
    self.net_info, self.module_list = create_modules(self.blocks)

  # Purpose of forward() is to 
  # 1. Calculate ouput
  # 2. Transform o/p detection map in a way that it can be preprocesses 
  def forward(self, x, CUDA):
    modules = self.block[1:]      
    # self.blocks[1:] is used instead of self.block since 1st element is a net block and isn't a part of forward pass
    outputs = {}
    # route & shortcut layers need output may from prev_layers, we cache the output feature map of every layer 

    write = 0
    for i, module in enumerate(modules):
      module_type = (module['type'])

      if module_type == 'convolutional' or module_type == 'upsample':
        x = self.module_list[i](x)

      elif module_type == 'route':
        """
        Here we have to acct for 2 cases - Route & shortcut
        - thus we use torch.cat to concatenate 2 feature maps 
          (w/ 2nd argument at pos_1 as we are concatenating along the depth)
        """
        layers = module["layers"]
        layers = [int(a) for a in layers]

        if (layers[0]) > 0:
          layers[0] = layers[0] - i

        if len(layers) == 1:
          x = outputs[i + (layers[0])]

        else:
          if (layers[1]) > 0:
            layers[1] = layers[1] - i

            map1 = outputs[i + layers[0]]
            map2 = outputs[i + layers[1]]

            x = torch.cat((map1, map2), 1)

      elif  module_type == "shortcut":
        from_ = int(module["from"])
        x = outputs[i-1] + outputs[i+from_]

